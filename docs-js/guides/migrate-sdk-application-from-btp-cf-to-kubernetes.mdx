---
id: kubernetes
title: Migrate your App from SAP BTP CF to Kubernetes with the SAP Cloud SDK for JavaScript
sidebar_label: Migrate to Kubernetes
description: Learn how to migrate your application from SAP BTP Cloud Foundry to Kubernetes with the SAP Cloud SDK for JavaScript
keywords:
  - sap
  - cloud
  - sdk
  - cloud native
  - cloud sdk
  - sap cloud sdk
  - kubernetes
---

# How to Migrate a Cloud Foundry Application to a Kubernetes Cluster

This how-to shows step-by-step what is necessary to migrate an application from Cloud Foundry to Kubernetes.

1. Decide what kind of environment you are creating.
   Is it a proof-of-concept (PoC), staging, or productive environment?
2. Prepare and set up your cluster with the sufficient services and service bindings to satisfy the environment's requirements.
3. Adapt your application to deploy to Kubernetes and make sure it can consume bound services from within your Kubernetes cluster.

Select the type of environment you're planning to build and click on it to jump to a corresponding section:

- [Simple PoC Environment](#simple-poc-environments)
  - If you want to create a PoC, this kind of environment will be sufficient for you.
    It's not recommended for productive use or long-running PoCs.
- [Staging Environments](#staging-environments)
  - For staging environments, you can create and bind services manually.
    This is primarily meant to try out different service setups.
- [Production Environments](#production-environments)
  - For production environments, you can create and bind services with reproducibility, longevity, and developer simplicity in mind.

## Simple PoC Environments

For a simple PoC, you can create and bind services in Cloud Foundry, or preferably even use already existing service bindings.

### Prerequisites

- [`kubectl`](https://kubernetes.io/docs/tasks/tools/)
- [`docker`](https://docs.docker.com/get-docker/)

### Create and Bind Services

If you want to create and bind _new_ services, you can deploy a `hello-world` app to SAP BTP Cloud Foundry and then bind services to this app.
Once that is done, access and copy the JSON representation of the bindings and create a secret in Kubernetes out of them.

The secret has to be in YAML format like in the example below.
Use the values from service binding's JSON data to replace the corresponding value in the `stringData` section of the YAML.

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: destination-service
type: Opaque
stringData:
  clientid: YOUR_CLIENT_ID
  clientsecret: YOUR_CLIENT_SECRET
  url: YOUR_URL
  identityzone: YOUR_IDENTITY_ZONE
  tenantid: YOUR_TENANT_ID
  tenantmode: YOUR_TENANT_MODE
  verificationkey: YOUR_VERIFICATION_KEY
  xsappname: YOUR_XS_APP_NAME
  uaadomain: YOUR_UAA_DOMAIN
  instanceid: YOUR_INSTANCE_ID
  uri: YOUR_URI
```

Once you are done, run `kubectl apply -f YOUR_BINDING.yml` to create the secret in your cluster.

Now let's take a look at how you can adapt your application to deploy it to Kubernetes and how it can consume services from inside of a Kubernetes cluster.
For this jump over to the [Deploy to Kubernetes](#deploy-to-kubernetes) section.

## Staging Environments

For a staging environment where you want to try out different services or experiment with service configurations, it is fine to use the following setup.

### Prerequisites

- [`smctl`](https://github.com/Peripli/service-manager-cli)
- [`svcat`](https://svc-cat.io/docs/cli/)
- [`helm`](https://helm.sh/docs/intro/install/)
- [`kubectl`](https://kubernetes.io/docs/tasks/tools/)
- [`docker`](https://docs.docker.com/get-docker/)

### Configure the Service Manager

First, create a service manager instance in Cloud Foundry with the `subaccount-admin` plan.

To be able to create a service manager, you will need sufficient privileges in the SAP BTP Cloud Foundry.
Follow the steps below to get them:

In the SAP BTP cockpit, navigate to your `subaccount` and choose **Security → Trust Configuration → SAP ID Service**.
Assign the "Subaccount Service Administrator" role collection to your email address.

Next, you need to login to the service manager control, also called `smctl`, and register your cluster

```
smctl login -a https://service-manager.YOUR_CF_API_ENDPOINT --param subdomain=YOUR_CF_SUBDOMAIN
smctl register-platform YOUR_CLUSTER_NAME kubernetes > service-manager-credentials.txt
```

The `service-manager-credentials.txt` contains sensitive data, keep it in a safe place.
You will need the `username` and `password` later on.

### Service Broker Registration

To make the services available in the Kubernetes cluster, you need to register a service broker into the Service Catalog of your Kubernetes cluster.
In SAP BTP Cloud Foundry the role of a service broker is fulfilled by the service manager.
Register it using the Service Catalog CLI, `svcat`.
To access the service manager on SAP BTP CF, you need to install the `service-broker-proxy` in your Kubernetes cluster.

Here's how you do it:

```bash
helm repo add peripli 'https://peripli.github.io'

kubectl create namespace service-broker-proxy

helm install service-broker-proxy peripli/service-broker-proxy-k8s \
  --namespace service-broker-proxy \
  --set image.tag=v0.3.2 \
  --set config.sm.url=YOUR_SERVICE_MANAGER_URL \
  --set sm.user=YOUR_SERVICE_MANAGER_USER \
  --set sm.password=YOUR_SERVICE_MANAGER_PASSWORD
```

After installing the proxy you have to wait a few seconds until it is fully operational.
Once the proxy is up, try running `svcat marketplace`, all the services available on SAP BTP CF should now be listed.

### Create and Bind Services

Now you can create service instances with the service catalog.
Let's create a destination service instance first.

```bash
svcat provision destination-service --class destination --plan lite
```

:::info
Notice how `destination-service` is just the name you give to this particular service instance, it could be anything.
:::

Now you could also create an XSUAA service instance.

```bash
svcat provision xsuaa-service --class xsuaa --plan broker
```

Finally, you need to bind the services to make them available to your application.

```bash
svcat bind destination-service
svcat bind xsuaa-service
```

Now let's take a look at how to adapt your application to deploy it to Kubernetes and make it consume services from inside of a Kubernetes cluster.
For this jump over to the [Deploy to Kubernetes](#deploy-to-kubernetes) section.

## Production Environments

For production environments, you need a reliable and reproducible way of configuring which services are running in your cluster.
To achieve that you can leverage the service operator.
With the service operator, all services are deployed via YAML files.
It makes services management a lot easier, scalable, and protected from errors in a long-term production environment.

### Prerequisites

- [`helm`](https://helm.sh/docs/intro/install/)
- [`kubectl`](https://kubernetes.io/docs/tasks/tools/)
- [`docker`](https://docs.docker.com/get-docker/)
- Use [Gardener](https://dashboard.garden.canary.k8s.ondemand.com/) for a Kubernetes Cluster with a load balancer enabled

### Configure Operator

To use the service operator, you'll need to set up at least basic TLS with a self-signed issuer certificate.
Run the command below to install the `cert-manager` to aid your TLS setup.

```bash
kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.4.0/cert-manager.yaml
```

To deploy the `cert-manager` into your cluster, install the `cert-manager` [CRDs](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/) with

```bash
kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.4.0/cert-manager.crds.yaml
```

Finally, add a self-signed certificate issuer to your cluster.
It can be done by adding the following YAML configuration:

```yaml
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  name: selfsigned-issuer
spec:
  selfSigned: {}
---
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: selfsigned-cluster-issuer
spec:
  selfSigned: {}
```

After you deployed the self-signed certificate issuer, you can start steps to deploy a service operator instance.

- First, you create a service manager instance in SAP BTP CF with the `service-operator-access` plan.
- After creating an instance you also need to bind it.
  The binding JSON should look similar to this:

```JSON
 {
     "clientid": "YOUR_CLIENT_ID",
     "clientsecret": "YOUR_CLIENT_SECRET",
     "url": "YOUR_URL",
     "xsappname": "YOUR_XS_APP_NAME",
     "sm_url": "YOUR_SERVICE_MANAGER_URL"
 }
```

Once you have the data from the service manager's binding, provide it to the helm CLI and deploy the service operator.
Helm is a package manager for Kubernetes.

```bash
helm upgrade --install sapbtp-operator https://github.com/SAP/sap-btp-service-operator/releases/download/YOUR_RELEASE/sapbtp-operator-YOUR_RELEASE.tgz \
    --create-namespace \
    --namespace=sapbtp-operator \
    --set manager.secret.clientid=YOUR_CLIENT_ID \
    --set manager.secret.clientsecret=YOUR_CLIENT_SECRET \
    --set manager.secret.url=YOUR_SERVICE_MANAGER_URL \
    --set manager.secret.tokenurl=YOUR_URL
```

### Create and Bind Services

Now that the service operator is running in your cluster, you can create services just like you would do in SAP BTP CF, but instead of the SAP BTP cockpit, you'll use YAML service definitions.

Here is an example of creating and binding a **Destination** service:

Creating an instance:

```yaml
apiVersion: services.cloud.sap.com/v1alpha1
kind: ServiceInstance
metadata:
  name: operator-destination-service
spec:
  serviceOfferingName: destination
  servicePlanName: lite
```

Binding the instance:

```yaml
apiVersion: services.cloud.sap.com/v1alpha1
kind: ServiceBinding
metadata:
  name: operator-destination-service
spec:
  serviceInstanceName: operator-destination-service
```

:::info
Notice that the `metadata -> name` property can be anything you want.
In this case, it's `operator-destination-service`.
Make sure it matches exactly to the `spec -> serviceInstanceName` field in the binding.
:::

Follow this pattern for all services your application needs to create and bind.

Now let's take a look at how to adapt your application to deploy it to Kubernetes and make it consume services from inside of a Kubernetes cluster.
For this jump over to the [Deploy to Kubernetes](#deploy-to-kubernetes) section.

## Deploy to Kubernetes

To deploy an application to Kubernetes you have to take a look at two things:

1. How to deploy your application to Kubernetes.
2. How to consume the services in your application from within Kubernetes.
   The example application will demonstrate this.

### Example Application

Here's the example application you are going to use: [Kubernetes app](https://github.com/SAP-samples/cloud-sdk-js/tree/main/samples/k8s-sample-application).
To figure out what has to be migrated, you have to take a look at the `manifest.yml`.

```yaml
applications:
  - name: k8s-e2e-app
    path: deployment/
    buildpacks:
      - nodejs_buildpack
    memory: 256M
    command: npm run start:prod
    random-route: true
    services:
      - destination-service
      - xsuaa-service
```

The configuration specifies:

- A node environment
- 256MB of memory
- Command to start the app
- Services needed to create and bind

This information is important in the following steps.

### Dockerfile

Kubernetes Pods are running container images.
You will a `Dockerfile` defining a container for your example application.
Then it can be deployed to one or more Kubernetes Pods.

```Dockerfile
FROM node:12-alpine

WORKDIR /workdir

COPY /deployment /workdir

RUN ["npm", "install", "--unsafe-perm"]

EXPOSE 3000
CMD ["npm", "run", "start:prod"]
```

You can see that your `Dockerfile` reflects the information from the `manifest.yml`.
You specify Node.js as an environment, `/deployment` as a path to copy the application to, and the command to run when the container image is fully loaded.

### Deployment Configuration

Next, you need to create a `deployment.yml` file, that contains the following data:

- resources definition your application needs
- container image, as well as registry secrets (in case your image was pushed to a private repository)
- service bindings you previously created

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sdkjs-e2e-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: sdkjs-e2e
  template:
    metadata:
      labels:
        app: sdkjs-e2e
    spec:
      containers:
        - name: sdkjs-e2e
          image: docker-cloudsdk.docker.repositories.sap.ondemand.com/k8s-e2e-app:latest
          resources:
            requests:
              memory: '256Mi'
              cpu: '500m'
            limits:
              memory: '512Mi'
              cpu: '1000m'
          ports:
            - containerPort: 3000
          volumeMounts:
            - name: destination-volume
              mountPath: '/etc/secrets/sapcp/destination/operator-destination-service'
              readOnly: true
            - name: xsuaa-volume
              mountPath: '/etc/secrets/sapcp/xsuaa/operator-xsuaa-service'
              readOnly: true
      imagePullSecrets:
        - name: regcred
      volumes:
        - name: destination-volume
          secret:
            secretName: operator-destination-service
        - name: xsuaa-volume
          secret:
            secretName: operator-xsuaa-service
```

You know from the `manifest.yml` file that the app needs 256MB of RAM on SAP BTP CF.
You can use it as guidance for Kubernetes by adding it to the `requests` field.
With Kubernetes, you can allow the resources to scale by also providing the `limits` field which in this case allows extending RAM up to 512MB.

Notice that the config uses `imagePullSecrets`, which is using the `regcred` secret.
The `regcred` secret contains your own registry credentials that you previously bound as a secret.
You can do this either by writing a `secret.yml` or directly in the CLI (though this will be in your `.bashrc` file) like this:

```bash
kubectl create secret docker-registry regcred \
  --docker-username=YOUR_DOCKER_USERNAME \
  --docker-password=YOUR_DOCKER_PASSWORD \
  --docker-email=YOUR_DOCKER_EMAIL
```

Finally, notice how you mount every service which you also had in the `manifest.yml` file, in this case, a **Destination** service and an **XSUAA** service.
To do this you use the `volumes` and `volumeMounts` properties.

The structure for the `volumes` property is:

```yaml
volumes:
  - name: YOUR_VOLUME_NAME
    secret:
      secretName: YOUR_SERVICE_BINDING
```

Here you create a secret, in this case, a service binding, available as a volume.
Next, you need to mount this secret at a specific path for it to be usable by the application.
For this, you follow a path convention provided by the [xsenv](https://www.npmjs.com/package/@sap/xsenv) library.

```yaml
volumeMounts:
  - name: YOUR_VOLUMNE_NAME
    mountPath: '/etc/secrets/sapcp/YOUR_SERVICE/YOUR_SERVICE_NAME'
    readOnly: true
```

### Deploy and Expose Your Application

To deploy your application, run:

`kubectl apply -f deployment.yml`

To access your application you have two options, either you expose it to the internet directly or port-forward to your local machine.

### Local Connection

Run the command `kubectl port-forward deployment YOUR_DEPLOYMENT :3000` on your local machine to enable port forwarding.
Your application will listen to port 3000.
Kubernetes finds an available port on your local machine and forwards port 3000 of your deployment to it.
Then you'll be able to make a call to your application via a provided link.

### Internet Facing Connection

Run the command below to expose your application to the internet.
It will use your cluster's IP address and port your application listens on.

:::danger

Exposing an application this way is good only for testing.
**Don't use it in production.**

:::

`kubectl expose deployment YOUR_DEPLOYMENT --type="LoadBalancer"`

If you want to expose your cluster under Domain name with TLS and/or basic authentication check out the [Configure TLS and obtain a Domain in SAP Gardener](#configure-tls-and-obtain-a-domain-in-sap-gardener) part for an SAP Gardener setup or the official Kubernetes [documentation](https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/) for a general setup.

## Create a Continuous Integration Pipeline

You can create a simple CI/CD pipeline with GitHub Actions or change your existing pipeline.
To automatically deploy your application into the Kubernetes cluster, two things are needed:

1. Automatic build the container image and deploy into the container repository
2. Automatic re-start of the Kubernetes Deployment

Step (1) can be achieved by building and pushing the container image with a technical user.
For Step (2) you need a technical user that is entitled to manage the cluster deployment.

1. [Create a service account](https://kubernetes.io/docs/reference/access-authn-authz/service-accounts-admin/) in your cluster.
2. Bind the `cluster-admin` cluster role to the service account.
   Alternative, create a more strict role.
3. Obtain the token and CA certificate from the secret that is automatically created for that service account.
4. Obtain the cluster API endpoint via command `kubectl cluster-info`.

You can now use the service account in your automation to connect to the cluster:

```bash
kubectl config set-cluster gardener --server=YOUR_CLUSTER_API_ENDPOINT
kubectl config set-context gardener --cluster=gardener
kubectl config use-context gardener
kubectl config view
kubectl --token=${{ secrets.KUBERNETES_SERVICE_TOKEN }} --certificate-authority YOUR_CA_CERT_PATH cluster-info
```

After completing the previous steps, run the command below.
It shutdowns all the Pods to restart them.

```bash
kubectl --token=${{ secrets.KUBERNETES_SERVICE_TOKEN }} --certificate-authority YOUR_CA_CERT_PATH rollout restart deployment/YOUR_DEPLOYMENT
```

If your Deployment is configured with `ImagePullStrategy: Always`, it will pull the updated image and use it.

## Configure TLS and Obtain a Domain in SAP Gardener

**Prerequisite:** Enable the NGINX Ingress add-on for your SAP Gardener cluster.

The fastest way to enable TLS and obtain a domain for your application is to create a Service, which contains your Deployment, and an Ingress, which handles the routing.
In SAP Gardener you can already specify your desired domain and the TLS will be managed for you, more on that later.

Create a Service that contains your Deployment and the port you want to expose as in example below:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: sdkjs-e2e-svc
spec:
  selector:
    app: sdkjs-e2e
  ports:
    - port: 8080
      targetPort: 3000
```

Next, check your Shoot cluster's `kubeconfig.yaml` for the configured DNS.
The Shoot cluster's `kubeconfig.yaml` should be located in your Gardener project's dashboard, under the YAML tab.
It should be a field that looks like this:

```yaml
spec:
  dns:
    domain: cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
```

Since you have the NGINX Ingress enabled, all your domains have to follow the pattern `*.ingress.YOUR_DNS`, for example

```yaml
e2e.ingress.cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
```

This is how your Ingress configuration file should look like:

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: sdkjs-e2e-ingress
  annotations:
    cert.gardener.cloud/purpose: managed
spec:
  tls:
    - hosts:
        - cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
        - e2e.ingress.cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
      secretName: secret-tls
  rules:
    - host: e2e.ingress.cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: sdkjs-e2e-svc
                port:
                  number: 8080
```

Notice how your Ingress uses the SAP Gardener annotations, which is important so that SAP Gardener manages TLS.

Next, you can see in the `spec.tls.hosts` part that it expose 2 domains.
The first one is your default domain, it's limited to a maximum of 64 characters.
Other domains can be any size, but should follow the Ingress pattern.

Notice the field `secretName: secret-tls` in this configuration.
All TLS certificates will be saved by SAP Gardener.
Finally look at how to serve the Service at the root of your subdomain.
This way the Service is exposed to the internet.

After a short delay, you should be able to access the mentioned domains via a valid TLS.

## Configure Basic Authentication

In case your application doesn't have built-in authentication, you can add basic authentication in front of the Ingress with the following steps:

1. Create a `htpasswd` file

```bash
htpasswd -c auth username
```

2. Create a secret out of this file

```bash
kubectl create secret generic YOUR_SECRET --from-file=auth
```

3. Add annotations to the Ingress.
   For your example, it should look like the following:

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: sdkjs-e2e-ingress
  annotations:
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: ingress-gate-auth
    nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required - This services is protected.'
    cert.gardener.cloud/purpose: managed
spec:
  tls:
    - hosts:
        - cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
        - e2e.ingress.cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
      secretName: secret-tls
  rules:
    - host: e2e.ingress.cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: sdkjs-e2e-svc
                port:
                  number: 8080
```

Notice how `ingress-gate-auth` is the name of the secret containing your password.
The text following the annotation `nginx.ingress.kubernetes.io/auth-realm:` contains a message, which is prompted when asking for credentials for the basic authentication.
Your basic authentication should now work.
Accessing any path should open an authentication window.

## On-Premise Connectivity

:::danger

On-Premise connectivity in Kubernetes is not available for SAP customers as of November 2022.

:::

To connect to on-premise systems inside a Kubernetes cluster, you need to use the connectivity proxy.
The following guide will show you what has to be done to create and use it.

1. You need to create a route for the connectivity proxy to use.
   This route needs to have TLS enabled.
   To enable TLS on SAP Gardener, refer to [configure TLS and obtain a domain in SAP Gardener](#configure-tls-and-obtain-a-domain-in-sap-gardener) section.
   If your cluster is not backed by SAP Gardener, refer to the official [Kubernetes documentation](https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/).

This example shows how to add a custom domain `connectivitytunnel.*` to the TLS section in SAP Gardener.
This creates a certificate for this domain automatically.

```yaml
spec:
  tls:
    - hosts:
        - cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
        - e2e.ingress.cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
        - connectivitytunnel.ingress.cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
      secretName: secret-tls
```

2. Add your CA certificate to the JVM trust store of the cloud connector.
   The CA certificate is stored in the TLS secret, in this case the name is `secret-tls`.

To access the information inside a secret, use the following code snippet:

```bash
kubectl get secret YOUR_SECRET -o go-template='{{range $k,$v := .data}}{{printf "%s: " $k}}{{if not $v}}{{$v}}{{else}}{{$v | base64decode}}{{end}}{{"\n"}}{{end}}'
```

Inside the secret should be a block prefixed with `ca.crt`, copy this certificate into a file and then follow [this guide](https://connect2id.com/blog/importing-ca-root-cert-into-jvm-trust-store) to add it to the JVM trust store of your cloud connector.

3. Create and bind the connectivity service with the `connectivty_proxy` plan.
   This guide explains how to do it above.
   Additionally, to bind the secret represented by Kubernetes native YAML format, you need to convert it to a JSON to be consumable by the connectivity proxy.
   If you use the PoC environment, save the binding as a secret, use the example below to guide you.
   Otherwise, you need to retrieve the binding first and then convert it to JSON before saving it as a secret.
   For that you need to retrieve the secret's content first, you can use the previous code snippet to retrieve the values of a secret for that.

Then save the JSON as a secret, here is an example:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: connectivity-proxy-service-key
type: Opaque
stringData:
  connectivity_key: '{
    "clientid": "YOUR_CLIENT_ID",
    "clientsecret": "YOUR_CLIENT_SECRET",
    "xsappname": "YOUR_XS_APP_NAME",
    "connectivity_service": {
        "CAs_path":"/api/v1/CAs",
        "CAs_signing_path":"/api/v1/CAs/signing",
        "api_path":"/api/v1",
        "tunnel_path":"/api/v1/tunnel",
        "url":"https://connectivity.cf.sap.hana.ondemand.com"
    },
    "subaccount_id": "YOUR_SUBACCOUNT_ID",
    "subaccount_subdomain": "YOUR_SUBACCOUNT_SUBDOMAIN",
    "token_service_domain": "YOUR_TOKEN_SERVICE_DOMAIN",
    "token_service_url": "YOUR_TOKEN_SERVICE_URL",
    "token_service_url_pattern": "https://{tenant}.authentication.sap.hana.ondemand.com/oauth/token",
    "token_service_url_pattern_tenant_key": "subaccount_subdomain"
}'
```

:::info

Note that the example used the `stringData` field type instead of the default `data` field type to benefit from automatic base64 encoding, instead of doing it ourselves.
This is a requirement of the connectivity proxy since it can't consume the data of the secret in YAML format.

:::

4. Download the CA certificate of the connectivity service and create a secret containing:

- the CA certificate of the connectivity service
- your private key
- your public certificate

The private key and public certificate are also stored in your TLS secret, use the previous code snippet to retrieve it from the secret and save them in separate files.
Finally, download the CA certificate with the following line:

```bash
curl https://connectivity.cf.sap.hana.ondemand.com/api/v1/CAs/signing -o connectivity_ca.crt
```

Now you can create the secret with this command:

```bash
kubectl create secret generic connectivity-tls --from-file=ca.crt=YOUR_CONNECTIVITY_CA_KEY.crt --from-file=tls.key=YOUR_PRIVATE_KEY.key --from-file=tls.crt=YOUR_PUBLIC_KEY.crt --namespace default
```

5. Create a secret that contains credentials to access the docker image which the connectivity proxy is using.

The image is located here: `deploy-releases.docker.repositories.sap.ondemand.com`

To create the registry secret, use the following command:

```bash
kubectl create secret docker-registry YOUR_REGISTRY_SECRET \
  --docker-username=YOUR_DOCKER_USERNAME \
  --docker-password=YOUR_DOCKER_PASSWORD \
  --docker-server=deploy-releases.docker.repositories.sap.ondemand.com
```

6. Create a `values.yaml` file containing the configuration that suits your desired operational mode of the connectivity proxy, for the available operational modes refer to the [documentation](https://help.sap.com/viewer/cca91383641e40ffbe03bdc78f00f681/Cloud/en-US/f3c1ef45db77489c8d039acc9530358f.html).
   For the specific content of the configuration refer to the [configuration guide](https://help.sap.com/viewer/cca91383641e40ffbe03bdc78f00f681/Cloud/en-US/eaa8204fc7484df984b3c321624827ff.html).

Here is an example for the "single tenant in a trusted environment" mode:

```yaml
deployment:
  replicaCount: 1
  image:
    pullSecret: 'proxy-secret'
ingress:
  tls:
    secretName: 'connectivity-tls'
config:
  integration:
    auditlog:
      mode: console
    connectivityService:
      serviceCredentialsKey: 'connectivity_key'
  tenantMode: dedicated
  subaccountId: 'YOUR_SUBACCOUNT_ID'
  subaccountSubdomain: 'YOUR_SUBACCOUNT_SUBDOMAIN'
  servers:
    businessDataTunnel:
      externalHost: 'connectivitytunnel.ingress.cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com'
      externalPort: 443
    proxy:
      rfcAndLdap:
        enabled: true
        enableProxyAuthorization: false
      http:
        enabled: true
        enableProxyAuthorization: false
        enableRequestTracing: true
      socks5:
        enableProxyAuthorization: false
```

7. For your application to reach on-premise destinations, it needs to provide the proxy settings and the token URL.
   You have to add them manually to the `secret` containing the service binding.

To do this, use the following code snippet:

```bash
kubectl edit secret YOUR_BINDING
```

Now you have to add the fields `onpremise_proxy_host` and `onpremise_proxy_port` and `url`.
The host has the pattern `connectivity-proxy.YOUR_NAMESPACE` which in this case is `connectivity-proxy.default`.
The default port is `20003`.
The `url` field should contain the same value as `token_service_url`.
Be aware that the values have to be encoded in base64, for example:

```yaml
onpremise_proxy_host: Y29ubmVjdGl2aXR5LXByb3h5LmRlZmF1bHQ=
onpremise_proxy_port: MjAwMDM=
url: aHR0cHM6Ly9teS1hcGkuYXV0aGVudGljYXRpb24uc2FwLmhhbmEub25kZW1hbmQuY29tCg==
```

8. Finally, add the binding to your `deployment.yml`, the same way you would add any other binding.

## Principal Propagation

You can use the Application Router also known as `approuter` to propagate a principal in Kubernetes and achieve multi-tenancy.
It works in a similar fashion to SAP BTP Cloud Foundry.

1. You need an XSUAA instance that can redirect to a Kubernetes URI.
   The parameter `redirect-uris` is important, however, if you use one parameter while creating a Service, you have to use all.

Below is an example using the SAP BTP Operator, to create an XSUAA with a very generic rule specifying the allowed URI with wildcards `https://*/**`.
For your application, it is recommended to point directly at your specific URI.

If you are not using the SAP BTP Operator, you still have to provide the same parameters but in a different format.
In Cloud Foundry, for instance, you have to provide these parameters in JSON format.

```yaml
apiVersion: services.cloud.sap.com/v1alpha1
kind: ServiceInstance
metadata:
  name: operator-xsuaa-service
spec:
  serviceOfferingName: xsuaa
  servicePlanName: application
  parameters:
    xsappname: kubernetes-xsuaa
    tenant-mode: dedicated
    scopes:
      - name: '$XSAPPNAME.Callback'
        description: 'With this scope set, the callbacks for tenant onboarding, offboarding and getDependencies can be called.'
        grant-as-authority-to-apps:
          - $XSAPPNAME(application,sap-provisioning,tenant-onboarding)
    role-templates:
      - name: TOKEN_EXCHANGE
        description: Token exchange
        scope-references:
          - uaa.user
      - name: 'MultitenancyCallbackRoleTemplate'
        description: 'Call callback-services of applications'
        scope-references:
          - '$XSAPPNAME.Callback'
    oauth2-configuration:
      grant-types:
        - authorization_code
        - client_credentials
        - password
        - refresh_token
        - urn:ietf:params:oauth:grant-type:saml2-bearer
        - user_token
        - client_x509
        - urn:ietf:params:oauth:grant-type:jwt-bearer
      redirect-uris:
        - https://*/**
```

2. Package the application router as a docker image so that it can run in Kubernetes, refer to the [documentation](https://blogs.sap.com/2020/04/03/sap-application-router/) for configuration details.

3. After creating a container image, create a Kubernetes Deployment and a Kubernetes Service to run and expose the application router.
   Below are two examples for an application router, a Pod and a Service.

First the Deployment:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: approuter
  labels:
    app: approuter
spec:
  replicas: 1
  selector:
    matchLabels:
      app: approuter
  template:
    metadata:
      labels:
        app: approuter
    spec:
      containers:
        - image: docker-cloudsdk.docker.repositories.sap.ondemand.com/k8s-approuter:latest
          resources:
            requests:
              memory: '256Mi'
              cpu: '250m'
            limits:
              memory: '512Mi'
              cpu: '500m'
          name: approuter
          volumeMounts:
            - name: xsuaa-volume
              mountPath: '/etc/secrets/sapcp/xsuaa/operator-xsuaa-service'
              readOnly: true
          env:
            - name: PORT
              value: '5000'
            - name: destinations
              value: '[{"name":"backend", "url":"http://sdkjs-e2e-svc:8080/", "forwardAuthToken": true}]'
      imagePullSecrets:
        - name: regcred
      volumes:
        - name: xsuaa-volume
          secret:
            secretName: operator-xsuaa-service
```

This example mounts the XSUAA service the same way as you do for apps using the SAP Cloud SDK.
It references the application running in your cluster.
Instead of an Ingress endpoint, it directly points at the Service.
This is possible because the application router runs in your cluster and can therefore use the Kubernetes native service discovery.

The Service configuration:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: approuter-svc
  labels:
    app: approuter
spec:
  ports:
    - port: 8080
      targetPort: 5000
  selector:
    app: approuter
```

4. Finally, configure the Ingress to create a session cookie that is consumed by the application router and point it at the `approuter` Service.
   To secure your application, remove all previous routes that pointed at your application's endpoints and only expose them through the application router.
   This way only users authenticated by your Identity Provider can access these endpoints.
   For that, specify the Service names in your approuter destinations' configuration and remove the rules you previously created for these endpoints in the Ingress.

   Depending on the Ingress controller you have to use different annotations.
   For the NGINX Ingress controller use the following annotations:

```yaml
nginx.ingress.kubernetes.io/affinity: cookie
nginx.ingress.kubernetes.io/proxy-read-timeout: '600'
nginx.ingress.kubernetes.io/session-cookie-name: JSESSIONID
```

An Ingress that only exposes the application router and is using the annotations is shown in the following example:

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: sdkjs-e2e-ingress
  annotations:
    nginx.ingress.kubernetes.io/affinity: 'cookie'
    nginx.ingress.kubernetes.io/proxy-read-timeout: '600'
    nginx.ingress.kubernetes.io/session-cookie-name: 'JSESSIONID'
    cert.gardener.cloud/purpose: managed
spec:
  tls:
    - hosts:
        - cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
        - e2e.ingress.cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
        - connectivitytunnel.ingress.cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
      secretName: secret-tls
  rules:
    - host: e2e.ingress.cloud-sdk-js.sdktests.shoot.canary.k8s-hana.ondemand.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: approuter-svc
                port:
                  number: 8080
```

5. Be aware that just like in SAP BTP Cloud Foundry, you have to collect the principal's JSON web token (JWT) from the authentication header after executing one of the requests with the typed client libraries.
   Here is an example utilizing the `retrieveJwt()` function:

<!-- vale Vale.Spelling = NO -->

```ts
import { Injectable } from '@nestjs/common';
import { retrieveJwt } from '@sap-cloud-sdk/connectivity';
import { Request } from 'express';
import { businessPartnerService } from './generated/business-partner-service';

@Injectable()
export class PrincipalBusinessPartnerService {
  async getFiveBusinessPartners(request: Request): Promise<BusinessPartner[]> {
    return BusinessPartner.requestBuilder()
      .getAll()
      .top(5)
      .execute({
        destinationName: 'MY-DESTINATION',
        jwt: retrieveJwt(request)
      });
  }
}
```
